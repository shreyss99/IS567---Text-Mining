{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a2eb8e",
   "metadata": {},
   "source": [
    "In this notebook, we will explore WordNet synsets, presenting a simple method for finding all mentions of all hyponyms of a given node in the WordNet hierarchy (e.g., finding all buildings in a text).\n",
    "\n",
    "Source code adapted from: https://github.com/dbamman/anlp21/blob/main/10.wordnet/ExploreWordNet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ffb2e",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e943d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, spacy\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner,parser'])\n",
    "nlp.remove_pipe('ner')\n",
    "nlp.remove_pipe('parser');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417a011",
   "metadata": {},
   "source": [
    "Get the synsets for a given word. The synsets here are roughly ordered by frequency of use (in a small tagged dataset), so that more frequent senses occur first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "synsets=wn.synsets('blue')\n",
    "for synset in synsets:\n",
    "    print (synset, synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma in wn.synset(\"blue.n.01\").lemmas():\n",
    "    print (lemma.name())\n",
    "\n",
    "# functions from http://www.nltk.org/howto/wordnet.html to get *all* of a synset's hyponym/hypernyms\n",
    "hypo = lambda s: s.hyponyms()\n",
    "hyper = lambda s: s.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the synsets that are hyponyms of the target synset (descendents in the WordNet hierarchy)\n",
    "list(wn.synset(\"blue.n.01\").closure(hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8df922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the synsets that are hyperyms (ancestors up the tree) of the target synset\n",
    "list(wn.synset(\"blue.n.01\").closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of words/phrases that comprise the hyponyms of a synset\n",
    "def get_words_in_hypo(synset):\n",
    "    words=set()\n",
    "    hyponym_synsets=list(synset.closure(hypo))\n",
    "    hyponym_synsets.append(synset)\n",
    "    for synset in hyponym_synsets:\n",
    "        for l in synset.lemmas():\n",
    "            word=l.name()\n",
    "            word=re.sub(\"_\", \" \", word)\n",
    "            words.add(word)\n",
    "    \n",
    "    return words\n",
    "\n",
    "get_words_in_hypo(wn.synset(\"color.n.01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given set of words, find each instance among a list of tokens already processed by spacy.  \n",
    "# return a list of token indexes that match.\n",
    "# note this only identifies single words, not multi-word phrases.\n",
    "def find_all_words_in_text(words, spacy_tokens):\n",
    "    all_matches=[]\n",
    "    for idx, token in enumerate(spacy_tokens):\n",
    "        if token.lemma_ in words:\n",
    "            all_matches.append(idx)\n",
    "    return all_matches\n",
    "\n",
    "# for a given set of token indexes, print out a window of words around each match, in the style of a concordance.\n",
    "def print_concordance(matches, spacy_tokens, window=3):\n",
    "    RED=\"\\x1b[31m\"\n",
    "    BLACK=\"\\x1b[0m\"\n",
    "    \n",
    "    spacing=window*10\n",
    "    for match in matches:\n",
    "        start=match-window\n",
    "        end=match+window+1\n",
    "        if start < 0:\n",
    "            start=0\n",
    "        if end > len(spacy_tokens):\n",
    "            end=len(spacy_tokens)\n",
    "        pre=' '.join([token.text for token in spacy_tokens[start:match]])\n",
    "        post=' '.join([token.text for token in spacy_tokens[match+1:end]])\n",
    "#         print(\"xtcyvubjn\")\n",
    "        print(\"%s %s%s%s %s\" % (pre.rjust(spacing), RED, spacy_tokens[match].text, BLACK, post))\n",
    "\n",
    "# read a text, replacing all whitespace sequences with a single space\n",
    "def read_text(filename):\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        return re.sub(\"\\s+\", \" \", file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a183a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Pride and Prejudice as an example\n",
    "book=read_text(\"Datasets/pride_and_prejudice.txt\")\n",
    "spacy_tokens=nlp(book)\n",
    "\n",
    "# search through all the tokens in the spacy_tokens argument to find any mention of words in the synset or any of its hyponyms\n",
    "def wordnet_search(synset, spacy_tokens):\n",
    "    targets=get_words_in_hypo(synset)\n",
    "    matches=find_all_words_in_text(targets, spacy_tokens)\n",
    "    print(len(matches),\"jkhbjkn\")\n",
    "    print_concordance(matches, spacy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78813e0c",
   "metadata": {},
   "source": [
    "Let's do a very coarse tagging of a document to find all of the mentions of a specific WordNet synset and all of its hyponyms. Using the functions above, find all the color terms in Pride and Prejudice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_search(wn.synset(\"color.n.01\"), spacy_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
